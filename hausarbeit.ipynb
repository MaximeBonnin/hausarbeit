{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausarbeit im Seminar Textanalyse WiSe 22/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden die Parteien definieiert und die Wahlprogramme (soweit vorhanden) eingelsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from wordscores3 import Wordscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL_BB</td>\n",
       "      <td>test test test Email sent, waiting for response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDF</td>\n",
       "      <td>Hochschulpolitik - Nicht mehr und nicht wenige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHG</td>\n",
       "      <td>Liebe Studis, \\nEs ist wieder so weit, die Hoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUSO</td>\n",
       "      <td>Liebe Wähler*innen,\\nvor euch seht ihr unser W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHG</td>\n",
       "      <td>AStA-Beiträge senken\\nAllgemeine Studiengebühr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LISTE_VOLT</td>\n",
       "      <td>Volt &amp; Die LISTE verstehen sich als linkes, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NORDCAMPUS</td>\n",
       "      <td>Mehr interdisziplinäre Zusammenarbeit\\nViele S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RCDS</td>\n",
       "      <td>Auslandsstudium\\nWer ein Semester im Ausland v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFD</td>\n",
       "      <td>Deutschland. Aber normal. Programm der Alterna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LINKE</td>\n",
       "      <td>Zeit zu handeln! Für soziale Sicherheit, Fried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party                                            program\n",
       "0      ALL_BB    test test test Email sent, waiting for response\n",
       "1         GDF  Hochschulpolitik - Nicht mehr und nicht wenige...\n",
       "2         GHG  Liebe Studis, \\nEs ist wieder so weit, die Hoc...\n",
       "3        JUSO  Liebe Wähler*innen,\\nvor euch seht ihr unser W...\n",
       "4         LHG  AStA-Beiträge senken\\nAllgemeine Studiengebühr...\n",
       "5  LISTE_VOLT  Volt & Die LISTE verstehen sich als linkes, pr...\n",
       "6  NORDCAMPUS  Mehr interdisziplinäre Zusammenarbeit\\nViele S...\n",
       "7        RCDS  Auslandsstudium\\nWer ein Semester im Ausland v...\n",
       "8         AFD  Deutschland. Aber normal. Programm der Alterna...\n",
       "9       LINKE  Zeit zu handeln! Für soziale Sicherheit, Fried..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTIES = [\n",
    "    \"ALL_BB\",\n",
    "    \"GDF\",\n",
    "    \"GHG\",\n",
    "    \"JUSO\",\n",
    "    \"LHG\",\n",
    "    \"LISTE_VOLT\",\n",
    "    \"NORDCAMPUS\",\n",
    "    \"RCDS\"\n",
    "]\n",
    "\n",
    "PROGRAMS = {}\n",
    "\n",
    "for party in PARTIES:\n",
    "    with open(f\"{party}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        file_content = f.read()\n",
    "        PROGRAMS[party] = file_content\n",
    "\n",
    "df = pd.DataFrame(PROGRAMS.items(), columns=[\"party\", \"program\"])\n",
    "\n",
    "# MARPOR data for referance texts\n",
    "df_afd = pd.read_csv(\"AfD2021.csv\")\n",
    "text = \" \".join(df_afd.text)\n",
    "new_row = [\"AFD\", text]\n",
    "df.loc[len(df)] = new_row\n",
    "\n",
    "df_afd = pd.read_csv(\"Linke2021.csv\")\n",
    "text = \" \".join(df_afd.text)\n",
    "new_row = [\"LINKE\", text]\n",
    "df.loc[len(df)] = new_row\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Im nächsten Schritt werden die Wahlprogramme gereinigt. Das Bedeutet, dass einige, für die Analyse unwichtige oder störende, Elemente gelöscht werden. Darunter zählen:\n",
    "- Zeilenumbrüche\n",
    "- großbuchstaben (werden klein geschrieben)\n",
    "- anderes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [email, senen, waiting, for, response]\n",
       "1    [hochschulpolitik, mehr, weniger, hochschulpol...\n",
       "2    [liebe, studi, weit, hochschulwahle, stehen, 1...\n",
       "3    [lieb, wähler*innen, sehen, wahlprogramm, hoch...\n",
       "4    [asta-beitrag, senken, allgemein, studiengebüh...\n",
       "5    [volt, liste, verstehen, linkes, progressiv, q...\n",
       "6    [mehr, interdisziplinär, zusammenarbeit, viele...\n",
       "7    [auslandsstudium, wer, semester, ausland, verb...\n",
       "8    [deutschland, normal, programm, alternative, f...\n",
       "9    [zeit, handeln, sozial, sicherheit, frieden, k...\n",
       "Name: program, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords definieren\n",
    "custom_stopwords = [\"test\"]\n",
    "stopwords_used = stopwords.words(\"german\") + custom_stopwords\n",
    "\n",
    "# lemmatization setup\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "\n",
    "for i, prog in df.program.items():\n",
    "    # lemma\n",
    "    nlp_doc = nlp(prog)\n",
    "    lemma_list = [x.lemma_ for x in nlp_doc]\n",
    "\n",
    "    # remove stopwords and lower\n",
    "    no_stopwords = [word.lower() for word in lemma_list if word.lower() not in stopwords_used]\n",
    "\n",
    "    # remove short tokens\n",
    "    min_len = 3\n",
    "    new_list = [word for word in no_stopwords if len(word) >= min_len]\n",
    "\n",
    "\n",
    "    # save to df\n",
    "    df.program[i] = new_list\n",
    "\n",
    "\n",
    "df.program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordscores berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_frequency_matrix(index: int) -> pd.DataFrame:\n",
    "    absolute_freq = pd.Series(df.program[index]).value_counts()\n",
    "    relative_freq = pd.Series(df.program[index]).value_counts(normalize=True)\n",
    "    word_freq_df = pd.DataFrame({\n",
    "        \"abs_freq\": absolute_freq,\n",
    "        \"rel_freq\": relative_freq\n",
    "    })\n",
    "\n",
    "    return(word_freq_df)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    create_word_frequency_matrix(i).to_csv(f\"inputdata/{df.party[i]}.csv\", header=False)\n",
    "\n",
    "#create_word_frequency_matrix(8).to_csv(\"inputdata/referenceCaseAfd.csv\",header=False)\n",
    "# create_word_frequency_matrix(9).to_csv(\"inputdata/referenceCaseLinke.csv\",header=False)\n",
    "\n",
    "#TODO think about research question (lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Uni\\WiSe 22-23\\Empirische Demokratieforschung\\Seminar_Methoden_der_Analyse_politischer_Texte_und_ihre_Anwendung\\python_code\\hausarbeit\\wordscores3.py:56: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  self.P_wr = self.F_wr.iloc[:, 1:].div(self.F_wr.sum(axis = 1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   word      score\n",
      "0      b'm\\xc3\\xbcssen'   1.000000\n",
      "1             b'mensch'   2.861789\n",
      "2             b'sollen'   5.116264\n",
      "3             b'sozial'   3.712750\n",
      "4                b'gut'   3.324352\n",
      "...                 ...        ...\n",
      "13077           b'jude'  10.000000\n",
      "13078    b'beleidigung'  10.000000\n",
      "13079   b'al-quds-tage'  10.000000\n",
      "13080    b'demonstrant'  10.000000\n",
      "13081            b'145'  10.000000\n",
      "\n",
      "[13082 rows x 2 columns]\n",
      "                  word  ALL_BB  GDF  GHG  JUSO  LHG  LISTE_VOLT  NORDCAMPUS  \\\n",
      "0             b'email'     0.2  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "1             b'senen'     0.2  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "2           b'waiting'     0.2  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "3               b'for'     0.2  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "4          b'response'     0.2  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "...                ...     ...  ...  ...   ...  ...         ...         ...   \n",
      "3264   b'z\\xc3\\xbcgig'     0.0  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "3265  b'landesverband'     0.0  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "3266    b'einheitlich'     0.0  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "3267     b'bundesweit'     0.0  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "3268   b'lehrangebote'     0.0  0.0  0.0   0.0  0.0         0.0         0.0   \n",
      "\n",
      "          RCDS  \n",
      "0     0.000000  \n",
      "1     0.000000  \n",
      "2     0.000000  \n",
      "3     0.000000  \n",
      "4     0.000000  \n",
      "...        ...  \n",
      "3264  0.001359  \n",
      "3265  0.001359  \n",
      "3266  0.001359  \n",
      "3267  0.001359  \n",
      "3268  0.001359  \n",
      "\n",
      "[3269 rows x 9 columns]\n",
      "\n",
      "Original scores (w/ 95CI):\n",
      "\n",
      "               score     lower     upper\n",
      "ALL_BB      1.220163 -3.057918  5.498245\n",
      "GDF         3.068557  2.874330  3.262784\n",
      "GHG         2.976534  2.809290  3.143779\n",
      "JUSO        3.611784  3.527149  3.696419\n",
      "LHG         3.344587  3.144878  3.544297\n",
      "LISTE_VOLT  3.359888  3.087723  3.632052\n",
      "NORDCAMPUS  3.431861  3.224875  3.638847\n",
      "RCDS        3.896916  3.684423  4.109409\n",
      "\n",
      "Transformed scores (w/ 95CI):\n",
      "\n",
      "                score      lower      upper\n",
      "ALL_BB     -11.619796 -44.905971  21.666380\n",
      "GDF          2.761875   1.250665   4.273085\n",
      "GHG          2.045880   0.744613   3.347148\n",
      "JUSO         6.988523   6.330007   7.647038\n",
      "LHG          4.909562   3.355696   6.463428\n",
      "LISTE_VOLT   5.028610   2.910995   7.146224\n",
      "NORDCAMPUS   5.588606   3.978124   7.199089\n",
      "RCDS         9.207031   7.553701  10.860360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_r = pd.DataFrame({'LINKE': 1.0, #TODO change values\n",
    "                   # 'referenceCase2': 5.0, \n",
    "                   'AFD': 10.0},\n",
    "                   index = ['score'])\n",
    "\n",
    "W = Wordscores(A_r=A_r)\n",
    "\n",
    "W.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textskalierungsvervahren sind explorativer, eigentlich cool\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68f718978781f2d56aeb50d49bc7bf5e93e7cb5af42a5cb959d972a377b115b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
