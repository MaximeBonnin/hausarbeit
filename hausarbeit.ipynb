{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausarbeit im Seminar Textanalyse WiSe 22/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden die Parteien definieiert und die Wahlprogramme (soweit vorhanden) eingelsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import GermanStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL_BB</td>\n",
       "      <td>test test test Email sent, waiting for response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDF</td>\n",
       "      <td>Hochschulpolitik - Nicht mehr und nicht wenige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHG</td>\n",
       "      <td>Liebe Studis, \\nEs ist wieder so weit, die Hoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUSO</td>\n",
       "      <td>Liebe Wähler*innen,\\nvor euch seht ihr unser W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHG</td>\n",
       "      <td>AStA-Beiträge senken\\nAllgemeine Studiengebühr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LISTE_VOLT</td>\n",
       "      <td>Volt &amp; Die LISTE verstehen sich als linkes, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NORDCAMPUS</td>\n",
       "      <td>Mehr interdisziplinäre Zusammenarbeit\\nViele S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RCDS</td>\n",
       "      <td>Auslandsstudium\\nWer ein Semester im Ausland v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party                                            program\n",
       "0      ALL_BB    test test test Email sent, waiting for response\n",
       "1         GDF  Hochschulpolitik - Nicht mehr und nicht wenige...\n",
       "2         GHG  Liebe Studis, \\nEs ist wieder so weit, die Hoc...\n",
       "3        JUSO  Liebe Wähler*innen,\\nvor euch seht ihr unser W...\n",
       "4         LHG  AStA-Beiträge senken\\nAllgemeine Studiengebühr...\n",
       "5  LISTE_VOLT  Volt & Die LISTE verstehen sich als linkes, pr...\n",
       "6  NORDCAMPUS  Mehr interdisziplinäre Zusammenarbeit\\nViele S...\n",
       "7        RCDS  Auslandsstudium\\nWer ein Semester im Ausland v..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTIES = [\n",
    "    \"ALL_BB\",\n",
    "    \"GDF\",\n",
    "    \"GHG\",\n",
    "    \"JUSO\",\n",
    "    \"LHG\",\n",
    "    \"LISTE_VOLT\",\n",
    "    \"NORDCAMPUS\",\n",
    "    \"RCDS\"\n",
    "]\n",
    "\n",
    "PROGRAMS = {}\n",
    "\n",
    "for party in PARTIES:\n",
    "    with open(f\"{party}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        file_content = f.read()\n",
    "        PROGRAMS[party] = file_content\n",
    "\n",
    "df = pd.DataFrame(PROGRAMS.items(), columns=[\"party\", \"program\"] )\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Im nächsten Schritt werden die Wahlprogramme gereinigt. Das Bedeutet, dass einige, für die Analyse unwichtige oder störende, Elemente gelöscht werden. Darunter zählen:\n",
    "- Zeilenumbrüche\n",
    "- großbuchstaben (werden klein geschrieben)\n",
    "- anderes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1564\\2861057112.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.program = df.program.str.replace(e, TO_REPLACE[e])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [test, test, test, email, sent, ,, waiting, fo...\n",
       "1    [hochschulpolitik, -, nicht, mehr, und, nicht,...\n",
       "2    [liebe, studis, ,, es, ist, wieder, so, weit, ...\n",
       "3    [liebe, wähler_innen, ,, vor, euch, seht, ihr,...\n",
       "4    [asta-beiträge, senken, allgemeine, studiengeb...\n",
       "5    [volt, und, die, liste, verstehen, sich, als, ...\n",
       "6    [mehr, interdisziplinäre, zusammenarbeit, viel...\n",
       "7    [auslandsstudium, wer, ein, semester, im, ausl...\n",
       "Name: program, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TO_REPLACE = {\n",
    "    \"&\": \"und\",\n",
    "    \"*\": \"_\"\n",
    "}\n",
    "\n",
    "# Alle Buchstaben klein schreiben\n",
    "df.program = df.program.str.lower()\n",
    "\n",
    "for e in TO_REPLACE:\n",
    "    df.program = df.program.str.replace(e, TO_REPLACE[e])\n",
    "\n",
    "\n",
    "# tokenize\n",
    "for i, prog in df.program.items():\n",
    "    df.program[i] = word_tokenize(prog, language=\"german\")\n",
    "# rerun cell above to fix data type if you get an error\n",
    "\n",
    "df.program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [email, sent, waiting, for, respons]\n",
       "1    [hochschulpolit, mehr, wenig, hochschulpolit, ...\n",
       "2    [lieb, studis, weit, hochschulwahl, steh, 16.,...\n",
       "3    [lieb, wahler_inn, seht, wahlprogramm, hochsch...\n",
       "4    [asta-beitrag, senk, allgemein, studiengebuhr,...\n",
       "5    [volt, list, versteh, link, progressiv, queer-...\n",
       "6    [mehr, interdisziplinar, zusammenarbeit, viel,...\n",
       "7    [auslandsstudium, wer, sem, ausland, verbringt...\n",
       "Name: program, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords definieren\n",
    "custom_stopwords = [\"test\"]\n",
    "stopwords_used = stopwords.words(\"german\") + custom_stopwords\n",
    "\n",
    "# stemming setup\n",
    "stemmer = GermanStemmer()\n",
    "\n",
    "\n",
    "for i, prog in df.program.items():\n",
    "    # remove stopwords\n",
    "    no_stopwords = [word for word in prog if word not in stopwords_used]\n",
    "\n",
    "    # remove short tokens\n",
    "    new_list = [word for word in no_stopwords if len(word) > 1]\n",
    "\n",
    "    # stemming\n",
    "    new_list = [stemmer.stem(word) for word in new_list]\n",
    "    # TODO studierende wird nicht zu studi \n",
    "\n",
    "    # save to df\n",
    "    df.program[i] = new_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ALL_BB\n",
      "         abs_freq  rel_freq\n",
      "email           1       0.2\n",
      "sent            1       0.2\n",
      "waiting         1       0.2\n",
      "for             1       0.2\n",
      "respons         1       0.2\n",
      "\n",
      "GDF\n",
      "         abs_freq  rel_freq\n",
      "studier        19  0.022432\n",
      "digital         9  0.010626\n",
      "student         9  0.010626\n",
      "studium         9  0.010626\n",
      "ford            8  0.009445\n",
      "...           ...       ...\n",
      "verbess         1  0.001181\n",
      "schutz          1  0.001181\n",
      "verbind         1  0.001181\n",
      "beweg           1  0.001181\n",
      "sieht           1  0.001181\n",
      "\n",
      "[549 rows x 2 columns]\n",
      "\n",
      "GHG\n",
      "                abs_freq  rel_freq\n",
      "studier               15  0.012909\n",
      "uni                   14  0.012048\n",
      "mehr                  13  0.011188\n",
      "universitat           13  0.011188\n",
      "student               12  0.010327\n",
      "...                  ...       ...\n",
      "manifestiert           1  0.000861\n",
      "1.                     1  0.000861\n",
      "generation             1  0.000861\n",
      "herausfordernd         1  0.000861\n",
      "wahlt                  1  0.000861\n",
      "\n",
      "[749 rows x 2 columns]\n",
      "\n",
      "JUSO\n",
      "                     abs_freq  rel_freq\n",
      "studier                    80  0.020571\n",
      "universitat                66  0.016971\n",
      "ford                       32  0.008228\n",
      "muss                       31  0.007971\n",
      "mehr                       29  0.007457\n",
      "...                       ...       ...\n",
      "corona                      1  0.000257\n",
      "gefahr                      1  0.000257\n",
      "oberst                      1  0.000257\n",
      "anwesenheitspflicht         1  0.000257\n",
      "erfolgreich                 1  0.000257\n",
      "\n",
      "[1752 rows x 2 columns]\n",
      "\n",
      "LHG\n",
      "                abs_freq  rel_freq\n",
      "student               12  0.012685\n",
      "liberal               11  0.011628\n",
      "hochschulgrupp         9  0.009514\n",
      "studier                9  0.009514\n",
      "dah                    8  0.008457\n",
      "...                  ...       ...\n",
      "bish                   1  0.001057\n",
      "konzentriert           1  0.001057\n",
      "hydrier                1  0.001057\n",
      "studentenleb           1  0.001057\n",
      "teuerungsrat           1  0.001057\n",
      "\n",
      "[627 rows x 2 columns]\n",
      "\n",
      "LISTE_VOLT\n",
      "                abs_freq  rel_freq\n",
      "studier               12  0.031250\n",
      "universitat           10  0.026042\n",
      "uni                    7  0.018229\n",
      "dafur                  6  0.015625\n",
      "mehr                   5  0.013021\n",
      "...                  ...       ...\n",
      "gremi                  1  0.002604\n",
      "international          1  0.002604\n",
      "gleichberecht          1  0.002604\n",
      "zusammenarbeit         1  0.002604\n",
      "gemacht                1  0.002604\n",
      "\n",
      "[299 rows x 2 columns]\n",
      "\n",
      "NORDCAMPUS\n",
      "             abs_freq  rel_freq\n",
      "nordcampus         13  0.019090\n",
      "studier            11  0.016153\n",
      "universitat         9  0.013216\n",
      "mehr                8  0.011747\n",
      "viel                7  0.010279\n",
      "...               ...       ...\n",
      "hieran              1  0.001468\n",
      "flachenmass         1  0.001468\n",
      "insgesamt           1  0.001468\n",
      "obwohl              1  0.001468\n",
      "film                1  0.001468\n",
      "\n",
      "[478 rows x 2 columns]\n",
      "\n",
      "RCDS\n",
      "             abs_freq  rel_freq\n",
      "student            23  0.030708\n",
      "hochschul          16  0.021362\n",
      "forschung          11  0.014686\n",
      "rcds                8  0.010681\n",
      "ausland             7  0.009346\n",
      "...               ...       ...\n",
      "bundesweit          1  0.001335\n",
      "entzieht            1  0.001335\n",
      "obliegt             1  0.001335\n",
      "form                1  0.001335\n",
      "lehrangebot         1  0.001335\n",
      "\n",
      "[474 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_word_frequency_matrix(index: int) -> pd.DataFrame:\n",
    "    absolute_freq = pd.Series(df.program[index]).value_counts()\n",
    "    relative_freq = pd.Series(df.program[index]).value_counts(normalize=True)\n",
    "    word_freq_df = pd.DataFrame({\n",
    "        # \"word\": absolute_freq.keys(),\n",
    "        \"abs_freq\": absolute_freq,\n",
    "        \"rel_freq\": relative_freq\n",
    "    })\n",
    "\n",
    "    return(word_freq_df)\n",
    "\n",
    "#TODO fix stemming/lemmatization (ask)\n",
    "#TODO think about research question (lol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68f718978781f2d56aeb50d49bc7bf5e93e7cb5af42a5cb959d972a377b115b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
