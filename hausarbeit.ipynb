{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausarbeit im Seminar Textanalyse WiSe 22/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden die Parteien definieiert und die Wahlprogramme (soweit vorhanden) eingelsen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import GermanStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL_BB</td>\n",
       "      <td>test test test Email sent, waiting for response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDF</td>\n",
       "      <td>Hochschulpolitik - Nicht mehr und nicht wenige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GHG</td>\n",
       "      <td>Liebe Studis, \\nEs ist wieder so weit, die Hoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUSO</td>\n",
       "      <td>Liebe Wähler*innen,\\nvor euch seht ihr unser W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHG</td>\n",
       "      <td>AStA-Beiträge senken\\nAllgemeine Studiengebühr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LISTE_VOLT</td>\n",
       "      <td>Volt &amp; Die LISTE verstehen sich als linkes, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NORDCAMPUS</td>\n",
       "      <td>Mehr interdisziplinäre Zusammenarbeit\\nViele S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RCDS</td>\n",
       "      <td>Auslandsstudium\\nWer ein Semester im Ausland v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party                                            program\n",
       "0      ALL_BB    test test test Email sent, waiting for response\n",
       "1         GDF  Hochschulpolitik - Nicht mehr und nicht wenige...\n",
       "2         GHG  Liebe Studis, \\nEs ist wieder so weit, die Hoc...\n",
       "3        JUSO  Liebe Wähler*innen,\\nvor euch seht ihr unser W...\n",
       "4         LHG  AStA-Beiträge senken\\nAllgemeine Studiengebühr...\n",
       "5  LISTE_VOLT  Volt & Die LISTE verstehen sich als linkes, pr...\n",
       "6  NORDCAMPUS  Mehr interdisziplinäre Zusammenarbeit\\nViele S...\n",
       "7        RCDS  Auslandsstudium\\nWer ein Semester im Ausland v..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARTIES = [\n",
    "    \"ALL_BB\",\n",
    "    \"GDF\",\n",
    "    \"GHG\",\n",
    "    \"JUSO\",\n",
    "    \"LHG\",\n",
    "    \"LISTE_VOLT\",\n",
    "    \"NORDCAMPUS\",\n",
    "    \"RCDS\"\n",
    "]\n",
    "\n",
    "PROGRAMS = {}\n",
    "\n",
    "for party in PARTIES:\n",
    "    with open(f\"{party}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        file_content = f.read()\n",
    "        PROGRAMS[party] = file_content\n",
    "\n",
    "df = pd.DataFrame(PROGRAMS.items(), columns=[\"party\", \"program\"] )\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Im nächsten Schritt werden die Wahlprogramme gereinigt. Das Bedeutet, dass einige, für die Analyse unwichtige oder störende, Elemente gelöscht werden. Darunter zählen:\n",
    "- Zeilenumbrüche\n",
    "- großbuchstaben (werden klein geschrieben)\n",
    "- anderes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6592\\2861057112.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.program = df.program.str.replace(e, TO_REPLACE[e])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [test, test, test, email, sent, ,, waiting, fo...\n",
       "1    [hochschulpolitik, -, nicht, mehr, und, nicht,...\n",
       "2    [liebe, studis, ,, es, ist, wieder, so, weit, ...\n",
       "3    [liebe, wähler_innen, ,, vor, euch, seht, ihr,...\n",
       "4    [asta-beiträge, senken, allgemeine, studiengeb...\n",
       "5    [volt, und, die, liste, verstehen, sich, als, ...\n",
       "6    [mehr, interdisziplinäre, zusammenarbeit, viel...\n",
       "7    [auslandsstudium, wer, ein, semester, im, ausl...\n",
       "Name: program, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TO_REPLACE = {\n",
    "    \"&\": \"und\",\n",
    "    \"*\": \"_\"\n",
    "}\n",
    "\n",
    "# Alle Buchstaben klein schreiben\n",
    "df.program = df.program.str.lower()\n",
    "\n",
    "for e in TO_REPLACE:\n",
    "    df.program = df.program.str.replace(e, TO_REPLACE[e])\n",
    "\n",
    "\n",
    "# tokenize\n",
    "for i, prog in df.program.items():\n",
    "    df.program[i] = word_tokenize(prog, language=\"german\")\n",
    "# rerun cell above to fix data type if you get an error\n",
    "\n",
    "df.program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [email, sent, waiting, for, respons]\n",
       "1    [hochschulpolit, mehr, wenig, hochschulpolit, ...\n",
       "2    [lieb, studis, weit, hochschulwahl, steh, 16.,...\n",
       "3    [lieb, wahler_inn, seht, wahlprogramm, hochsch...\n",
       "4    [asta-beitrag, senk, allgemein, studiengebuhr,...\n",
       "5    [volt, list, versteh, link, progressiv, queer-...\n",
       "6    [mehr, interdisziplinar, zusammenarbeit, viel,...\n",
       "7    [auslandsstudium, wer, sem, ausland, verbringt...\n",
       "Name: program, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords definieren\n",
    "custom_stopwords = [\"test\"]\n",
    "stopwords_used = stopwords.words(\"german\") + custom_stopwords\n",
    "\n",
    "# stemming setup\n",
    "stemmer = GermanStemmer()\n",
    "\n",
    "\n",
    "for i, prog in df.program.items():\n",
    "    # remove stopwords\n",
    "    no_stopwords = [word for word in prog if word not in stopwords_used]\n",
    "\n",
    "    # remove short tokens\n",
    "    new_list = [word for word in no_stopwords if len(word) > 1]\n",
    "\n",
    "    # stemming\n",
    "    new_list = [stemmer.stem(word) for word in new_list]\n",
    "    # TODO studierende wird nicht zu studi \n",
    "\n",
    "    # save to df\n",
    "    df.program[i] = new_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studier               2.2\n",
       "digital               1.1\n",
       "student               1.1\n",
       "studium               1.1\n",
       "ford                  0.9\n",
       "mehr                  0.9\n",
       "imm                   0.9\n",
       "setz                  0.9\n",
       "campus                0.9\n",
       "geht                  0.8\n",
       "bess                  0.8\n",
       "universitat           0.7\n",
       "we                    0.7\n",
       "steht                 0.7\n",
       "viel                  0.7\n",
       "gemeinschaft          0.6\n",
       "and                   0.6\n",
       "bedeutet              0.6\n",
       "sqm                   0.6\n",
       "studierendenschaft    0.6\n",
       "fachschaft            0.6\n",
       "gemeinsam             0.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_series = pd.Series(df.program[1]).value_counts(normalize=True).mul(100).round(1)\n",
    "counts_series\n",
    "percent_cutoff = 0.5 # %\n",
    "new_series = counts_series[counts_series > percent_cutoff]\n",
    "new_series\n",
    "#TODO fix stemming/lemmatization (ask)\n",
    "#TODO think about research question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pygame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68f718978781f2d56aeb50d49bc7bf5e93e7cb5af42a5cb959d972a377b115b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
